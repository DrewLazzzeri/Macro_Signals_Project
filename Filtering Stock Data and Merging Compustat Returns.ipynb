{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "eKyysAL7h3uFB5jLX6EtHw",
     "type": "CODE"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: wrds in c:\\users\\andrew_lazzeri\\appdata\\roaming\\python\\python39\\site-packages (3.1.2)\n",
      "Requirement already satisfied: sqlalchemy in c:\\programdata\\anaconda3\\lib\\site-packages (from wrds) (1.4.32)\n",
      "Requirement already satisfied: mock in c:\\programdata\\anaconda3\\lib\\site-packages (from wrds) (4.0.3)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from wrds) (1.22.4)\n",
      "Requirement already satisfied: pandas in c:\\programdata\\anaconda3\\lib\\site-packages (from wrds) (1.4.2)\n",
      "Requirement already satisfied: psycopg2-binary in c:\\users\\andrew_lazzeri\\appdata\\roaming\\python\\python39\\site-packages (from wrds) (2.9.5)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas->wrds) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas->wrds) (2.8.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from sqlalchemy->wrds) (1.1.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->wrds) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 23.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#General dataframe\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import scipy.stats as scistat\n",
    "from datetime import datetime\n",
    "\n",
    "#Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#Install and import wrds\n",
    "!pip install wrds\n",
    "import wrds\n",
    "\n",
    "#ScipyStats\n",
    "from scipy.stats import mstats\n",
    "from scipy.stats.mstats import winsorize\n",
    "\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from scipy.stats.mstats import winsorize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upload the Xu/Kelly Data\n",
    "\n",
    "The below workflow uploads the original Kelly study's data in chunks for further processing.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "uvmevsFmCyJEUHspVID2NF",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "filename = \"C:/Users/andrew_lazzeri/Desktop/Project_Files/Data Upload/datashare.csv\"\n",
    "df_test = pd.read_csv(filename, nrows = 1)\n",
    "col_conv = {c: np.float32 for c in df_test.columns}\n",
    "col_conv['permno'] = np.int32\n",
    "col_conv['DATE'] = np.int32 #May want to change to date time\n",
    "del df_test \n",
    "\n",
    "mylist = []\n",
    "\n",
    "for chunk in  pd.read_csv(filename, sep=',', chunksize=5000, error_bad_lines = False, engine='python', dtype=col_conv):\n",
    "    mylist.append(chunk)\n",
    "\n",
    "big_data = pd.concat(mylist, axis= 0)\n",
    "del mylist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upload Monthly Fama French Data to Obtain the Risk Free Rate for Excess Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RiskFree</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1963-07-31</th>\n",
       "      <td>0.0027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1963-08-31</th>\n",
       "      <td>0.0025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1963-09-30</th>\n",
       "      <td>0.0027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1963-10-31</th>\n",
       "      <td>0.0029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1963-11-30</th>\n",
       "      <td>0.0027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-31</th>\n",
       "      <td>0.0019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-30</th>\n",
       "      <td>0.0019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-31</th>\n",
       "      <td>0.0023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-30</th>\n",
       "      <td>0.0029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-31</th>\n",
       "      <td>0.0033</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>714 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            RiskFree\n",
       "Date                \n",
       "1963-07-31    0.0027\n",
       "1963-08-31    0.0025\n",
       "1963-09-30    0.0027\n",
       "1963-10-31    0.0029\n",
       "1963-11-30    0.0027\n",
       "...              ...\n",
       "2022-08-31    0.0019\n",
       "2022-09-30    0.0019\n",
       "2022-10-31    0.0023\n",
       "2022-11-30    0.0029\n",
       "2022-12-31    0.0033\n",
       "\n",
       "[714 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pandas.tseries.offsets import Day, MonthEnd\n",
    "\n",
    "rf_df_path = \"C:/Users/andrew_lazzeri/Desktop/Project_Files/Data Upload/F-F_Research_Data_5_Factors_2x3.csv\"\n",
    "risk_free_df = pd.read_csv(rf_df_path, header = 2, parse_dates = ['Unnamed: 0'])\n",
    "risk_free_df = risk_free_df.iloc[0:714]\n",
    "risk_free_df = risk_free_df[['Unnamed: 0', 'RF']]\n",
    "risk_free_df.columns = ['Date', 'RiskFree']\n",
    "risk_free_df['RiskFree'] = risk_free_df['RiskFree'].astype(float)/100\n",
    "risk_free_df['Date'] = pd.to_datetime(risk_free_df['Date'], format='%Y%m', errors='coerce')\n",
    "risk_free_df['Date'] = risk_free_df['Date'] + MonthEnd() \n",
    "risk_free_df = risk_free_df.set_index(['Date'])\n",
    "risk_free_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Log on to WRDS\n",
    "\n",
    "Here you have to establish a connection to WRDS and use your password.  I have a specific login and password setup I didn't include here so I didn't forget and send it out to the public."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "GqaXwETzJEbQidy8B6R3OZ",
     "type": "CODE"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your WRDS username [andrew_lazzeri]:lazz0402\n",
      "Enter your password:········\n",
      "WRDS recommends setting up a .pgpass file.\n",
      "Create .pgpass file now [y/n]?: n\n",
      "You can create this file yourself at any time\n",
      "with the create_pgpass_file() function.\n",
      "Loading library list...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "#lazz0402\n",
    "#Tignale04021986!\n",
    "\n",
    "conn = wrds.Connection()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The below functions append Compustat total returns to the original dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "UJLRk2WnyxdJeDOTsJZAuk",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "#Extract the returns from Compustat\n",
    "def where_string(permno_list):\n",
    "    \n",
    "    \"\"\"\n",
    "    Input: List of permnos (security specific identifiers) \n",
    "    -creates a list of permnos to search in the WRDS SQL query \n",
    "    -links them with an \"OR permno =\" which allows pulling multiple permnos \n",
    "    from a Compustat SQL search\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    ticker_str = \"where permno = \" + str(permno_list[0])\n",
    "    for i in range(1, len(permno_list)):\n",
    "        ticker_str += \" OR permno = \" + str(permno_list[i])\n",
    "    return ticker_str\n",
    "\n",
    "def return_pull(permno_list):\n",
    "    \n",
    "    \"\"\"\n",
    "    -Takes the permno_list and pulls the returns for each security in that list since 1957\n",
    "    -Returns a pivoted dataframe with the permno as the columns, date rows, total return values\n",
    "    \"\"\"\n",
    "\n",
    "    subtr = where_string(permno_list)\n",
    "    SQL_str = \"select permno, date, ret from crsp.msf \" + subtr + \" and date>='01/01/1957'\"\n",
    "    cstat_pull = conn.raw_sql(SQL_str, \n",
    "                     date_cols=['date'])\n",
    "    return cstat_pull.pivot(values = 'ret', index = ['date'], columns = 'permno')\n",
    "\n",
    "def fwd_return(df, m_fwd):\n",
    "    \"\"\"\n",
    "    Takes a pivoted dataframe and calculates the forward returns m_fwd periods\n",
    "    \"\"\"\n",
    "    \n",
    "    iter_df = df.copy()\n",
    "    iter_df = np.log(iter_df.shift(m_fwd)) - np.log(iter_df)\n",
    "    return iter_df\n",
    "\n",
    "def melt_df(df, m_string):\n",
    "    \"\"\"\n",
    "    A simple helper function to melt the dataframe repeatedly\n",
    "    \"\"\"\n",
    "    idx_list = list(df.index)\n",
    "    melt_df = pd.melt(df)\n",
    "    melt_df['date'] = (idx_list * df.shape[1])\n",
    "    melt_df.columns = ['permno', str(m_string)+'m_fwd_ret', 'date']\n",
    "    return melt_df\n",
    "\n",
    "def return_merge(permno_list, risk_free_df):\n",
    "    \"\"\"\n",
    "    -Pulls the return dataframe and then creates a cumulative indexed return for each security. \n",
    "    -calculates the forward returns over various horizons.  \n",
    "    -Forward returns are then melted from a pivoted dataframes\n",
    "    -Pivoted dataframes consolidated into a series of fwd return columns \n",
    "    \"\"\"\n",
    "    \n",
    "    #Pull the returns information from Compustat and produce a cumulative total return index\n",
    "    return_df =  return_pull(permno_list)\n",
    "    return_df = return_df.reset_index()\n",
    "    return_df['date'] = pd.to_datetime(return_df['date']) + MonthEnd() \n",
    "    return_df = pd.melt(return_df, id_vars = 'date')\n",
    "    return_df = return_df.set_index(['date'])\n",
    "    return_df = return_df.join(risk_free_df)\n",
    "    return_df['ExcessRet'] = return_df['value'].astype(float) - return_df['RiskFree'].astype(float)\n",
    "    return_df = return_df.reset_index()\n",
    "    return_df.columns = ['date', 'permno', 'value', 'RiskFree', 'ExcessRet']\n",
    "    return_df = return_df[['date', 'permno', 'ExcessRet']]\n",
    "    return_df = return_df.reset_index().pivot_table(index = 'date', columns = 'permno', values = 'ExcessRet')\n",
    "    return_df = return_df + 1\n",
    "    c_return_df = return_df.cumprod()\n",
    "    \n",
    "    #Setup fwd returns\n",
    "    fwd_1m_ret = fwd_return(c_return_df, -1)\n",
    "    fwd_12m_ret = fwd_return(c_return_df, -12)\n",
    "    \n",
    "    #Melted dfs\n",
    "    ret_m = melt_df(c_return_df, 0)\n",
    "    fwd_1m_ret_m = melt_df(fwd_1m_ret, 1)\n",
    "    fwd_12m_ret_m = melt_df(fwd_12m_ret, 12)\n",
    "    \n",
    "    #Consolidate dataframe\n",
    "    final_df = ret_m\n",
    "    df_list = [fwd_1m_ret_m, fwd_12m_ret_m]\n",
    "    for ret_df in df_list: \n",
    "        final_df = final_df.merge(ret_df, left_on = ['permno', 'date'], right_on = ['permno', 'date'])\n",
    "\n",
    "    return final_df.dropna(subset=['1m_fwd_ret'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32793"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "permno_list = list(set(big_data['permno'].to_list()))\n",
    "len(permno_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "append_df = return_merge(permno_list, risk_free_df)\n",
    "append_df.to_csv('C:/Users/andrew_lazzeri/Desktop/Project_Files/Data Upload/return dfs/append_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef small_pulls(permno_list, risk_free_df):\\n    return_df = pd.DataFrame()\\n    len_permno = len(permno_list)\\n    samples = list(range(0, len_permno, 10000))\\n    for i in range(1, len(samples)):\\n        iter_returns = return_merge(permno_list[samples[i-1]:samples[i]], risk_free_df)\\n        return_df = pd.concat([return_df, iter_returns])\\n         \\n    return return_df\\n\\nappend_df = small_pulls(permno_list, risk_free_df)\\n\\nappend_df.to_csv('C:/Users/andrew_lazzeri/Desktop/Project_Files/Data Upload/return dfs/append_df.csv')\\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "def small_pulls(permno_list, risk_free_df):\n",
    "    return_df = pd.DataFrame()\n",
    "    len_permno = len(permno_list)\n",
    "    samples = list(range(0, len_permno, 10000))\n",
    "    for i in range(1, len(samples)):\n",
    "        iter_returns = return_merge(permno_list[samples[i-1]:samples[i]], risk_free_df)\n",
    "        return_df = pd.concat([return_df, iter_returns])\n",
    "         \n",
    "    return return_df\n",
    "\n",
    "append_df = small_pulls(permno_list, risk_free_df)\n",
    "\n",
    "append_df.to_csv('C:/Users/andrew_lazzeri/Desktop/Project_Files/Data Upload/return dfs/append_df.csv')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "IGKTSvESNNcg3G2OwkKHRc",
     "type": "CODE"
    }
   },
   "source": [
    "#### Once run, append the fwd total return data to the feature data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "zqp9s7rFf9J8Lyqf1X1xmp",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "big_data['DATE'] = pd.to_datetime(big_data['DATE'])\n",
    "\n",
    "#Join the two dataframes\n",
    "big_data = big_data.merge(append_df, how = 'left', left_on = ['permno', 'DATE'], right_on = ['permno', 'date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_data.to_csv('C:/Users/andrew_lazzeri/Desktop/Project_Files/Data Upload/final_cross_section_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "datalore": {
   "base_environment": "default",
   "computation_mode": "JUPYTER",
   "package_manager": "pip",
   "packages": [],
   "version": 1
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
