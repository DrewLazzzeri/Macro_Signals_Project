{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "eKyysAL7h3uFB5jLX6EtHw",
     "type": "CODE"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: wrds in c:\\users\\andrew_lazzeri\\appdata\\roaming\\python\\python311\\site-packages (3.1.6)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\envs\\andrew\\lib\\site-packages (from wrds) (1.23.5)\n",
      "Requirement already satisfied: pandas in c:\\programdata\\anaconda3\\envs\\andrew\\lib\\site-packages (from wrds) (1.5.3)\n",
      "Requirement already satisfied: psycopg2-binary in c:\\users\\andrew_lazzeri\\appdata\\roaming\\python\\python311\\site-packages (from wrds) (2.9.6)\n",
      "Requirement already satisfied: scipy in c:\\programdata\\anaconda3\\envs\\andrew\\lib\\site-packages (from wrds) (1.10.1)\n",
      "Requirement already satisfied: sqlalchemy<2 in c:\\users\\andrew_lazzeri\\appdata\\roaming\\python\\python311\\site-packages (from wrds) (1.4.47)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\programdata\\anaconda3\\envs\\andrew\\lib\\site-packages (from sqlalchemy<2->wrds) (2.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\programdata\\anaconda3\\envs\\andrew\\lib\\site-packages (from pandas->wrds) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\envs\\andrew\\lib\\site-packages (from pandas->wrds) (2022.7)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\envs\\andrew\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->wrds) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#General dataframe\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#import statsmodels.api as sm\n",
    "import scipy.stats as scistat\n",
    "from datetime import datetime\n",
    "\n",
    "#Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#Install and import wrds\n",
    "!pip install wrds\n",
    "import wrds\n",
    "\n",
    "#ScipyStats\n",
    "from scipy.stats import mstats\n",
    "from scipy.stats.mstats import winsorize\n",
    "\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from scipy.stats.mstats import winsorize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upload the Xu/Kelly Data\n",
    "\n",
    "The below workflow uploads the original Kelly study's data in chunks for further processing.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_align(df):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function to align all dates to the end of the month across various databases\n",
    "    \"\"\"\n",
    "    exceptions = []\n",
    "    date_list = sorted(list(set(df['DATE'])))\n",
    "    date_convert = {}\n",
    "    for date in date_list:\n",
    "        try:\n",
    "            date_convert[date] = pd.offsets.MonthEnd().rollforward(date)\n",
    "        except:\n",
    "            exceptions.append(date)\n",
    "            continue \n",
    "            \n",
    "    df['DATE'] = df['DATE'].replace(date_convert)\n",
    "    return df, exceptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "uvmevsFmCyJEUHspVID2NF",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "filename = \"C:/Users/andrew_lazzeri/Desktop/Project_Files/Data Upload/datashare.csv\"\n",
    "df_test = pd.read_csv(filename, nrows = 1)\n",
    "col_conv = {c: np.float32 for c in df_test.columns}\n",
    "col_conv['permno'] = np.int32\n",
    "col_conv['DATE'] = np.int32 #May want to change to date time\n",
    "del df_test \n",
    "\n",
    "mylist = []\n",
    "\n",
    "for chunk in  pd.read_csv(filename, sep=',', chunksize=5000, error_bad_lines = False, engine='python', dtype=col_conv):\n",
    "    mylist.append(chunk)\n",
    "\n",
    "big_data = pd.concat(mylist, axis= 0)\n",
    "del mylist\n",
    "\n",
    "big_data['DATE'] = pd.to_datetime(big_data['DATE'].astype(str))\n",
    "big_data, exceptions = date_align(big_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upload Monthly Fama French Data to Obtain the Risk Free Rate for Excess Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from pandas.tseries.offsets import Day, MonthEnd\n",
    "\n",
    "rf_df_path = \"C:/Users/andrew_lazzeri/Desktop/Project_Files/Data Upload/F-F_Research_Data_5_Factors_2x3.csv\"\n",
    "risk_free_df = pd.read_csv(rf_df_path, header = 2, parse_dates = ['Unnamed: 0'])\n",
    "risk_free_df = risk_free_df.iloc[0:714]\n",
    "risk_free_df = risk_free_df[['Unnamed: 0', 'RF']]\n",
    "\n",
    "\n",
    "risk_free_df.columns = ['Date', 'RiskFree']\n",
    "risk_free_df['RiskFree'] = risk_free_df['RiskFree'].astype(float)/100\n",
    "risk_free_df['DATE'] = pd.to_datetime(risk_free_df['Date'], format='%Y%m', errors='coerce')\n",
    "risk_free_df, exceptions = date_align(risk_free_df)\n",
    "risk_free_df['Date'] = risk_free_df['DATE']\n",
    "risk_free_df = risk_free_df.drop(['DATE'], axis=1)\n",
    "risk_free_df = risk_free_df.set_index(['Date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Log on to WRDS\n",
    "\n",
    "Here you have to establish a connection to WRDS and use your password.  I have a specific login and password setup I didn't include here so I didn't forget and send it out to the public."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "GqaXwETzJEbQidy8B6R3OZ",
     "type": "CODE"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your WRDS username [andrew_lazzeri]:lazz0402\n",
      "Enter your password:········\n",
      "WRDS recommends setting up a .pgpass file.\n",
      "Create .pgpass file now [y/n]?: n\n",
      "You can create this file yourself at any time with the create_pgpass_file() function.\n",
      "Loading library list...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "#lazz0402\n",
    "#Tignale04021986!\n",
    "\n",
    "conn = wrds.Connection()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The below functions append Compustat total returns to the original dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "UJLRk2WnyxdJeDOTsJZAuk",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "#Extract the returns from Compustat\n",
    "def where_string(permno_list):\n",
    "    \n",
    "    \"\"\"\n",
    "    Input: List of permnos (security specific identifiers) \n",
    "    -creates a list of permnos to search in the WRDS SQL query \n",
    "    -links them with an \"OR permno =\" which allows pulling multiple permnos \n",
    "    from a Compustat SQL search\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    ticker_str = \"where permno = \" + str(permno_list[0])\n",
    "    for i in range(1, len(permno_list)):\n",
    "        ticker_str += \" OR permno = \" + str(permno_list[i])\n",
    "    return ticker_str\n",
    "\n",
    "def return_pull(permno_list):\n",
    "    \n",
    "    \"\"\"\n",
    "    -Takes the permno_list and pulls the returns for each security in that list since 1957\n",
    "    -Returns a pivoted dataframe with the permno as the columns, date rows, total return values\n",
    "    \"\"\"\n",
    "\n",
    "    subtr = where_string(permno_list)\n",
    "    SQL_str = \"select permno, date, ret from crsp.msf \" + subtr + \" and date>='01/01/1957'\"\n",
    "    cstat_pull = conn.raw_sql(SQL_str, \n",
    "                     date_cols=['date'])\n",
    "    return cstat_pull.pivot(values = 'ret', index = ['date'], columns = 'permno')\n",
    "\n",
    "def fwd_return(df, m_fwd):\n",
    "    \"\"\"\n",
    "    Takes a pivoted dataframe and calculates the forward returns m_fwd periods\n",
    "    \"\"\"\n",
    "    \n",
    "    iter_df = df.copy()\n",
    "    iter_df = np.log(iter_df.shift(m_fwd)) - np.log(iter_df)\n",
    "    return iter_df\n",
    "\n",
    "def melt_df(df, m_string):\n",
    "    \"\"\"\n",
    "    A simple helper function to melt the dataframe repeatedly\n",
    "    \"\"\"\n",
    "    idx_list = list(df.index)\n",
    "    melt_df = pd.melt(df)\n",
    "    melt_df['date'] = (idx_list * df.shape[1])\n",
    "    melt_df.columns = ['permno', str(m_string)+'m_fwd_ret', 'date']\n",
    "    return melt_df\n",
    "\n",
    "def return_merge(permno_list, risk_free_df):\n",
    "    \"\"\"\n",
    "    -Pulls the return dataframe and then creates a cumulative indexed return for each security. \n",
    "    -calculates the forward returns over various horizons.  \n",
    "    -Forward returns are then melted from a pivoted dataframes\n",
    "    -Pivoted dataframes consolidated into a series of fwd return columns \n",
    "    \"\"\"\n",
    "    \n",
    "    #Pull the returns information from Compustat and produce a cumulative total return index\n",
    "    return_df =  return_pull(permno_list)\n",
    "    return_df = return_df.reset_index()\n",
    "    return_df['DATE'] = return_df['date']\n",
    "    return_df, exceptions = date_align(return_df)\n",
    "    return_df['Date'] = return_df['DATE']\n",
    "    return_df = return_df.drop(['DATE', 'date'], axis=1)\n",
    "    return_df = pd.melt(return_df, id_vars = 'Date')\n",
    "    return_df = return_df.set_index(['Date'])\n",
    "    return_df = return_df.join(risk_free_df)\n",
    "    return_df['ExcessRet'] = return_df['value'].astype(float) - return_df['RiskFree'].astype(float)\n",
    "    return_df = return_df.reset_index()\n",
    "    return_df.columns = ['date', 'permno', 'value', 'RiskFree', 'ExcessRet']\n",
    "    return_df = return_df[['date', 'permno', 'ExcessRet']]\n",
    "    return_df = return_df.reset_index().pivot_table(index = 'date', columns = 'permno', values = 'ExcessRet')\n",
    "    return_df = return_df + 1\n",
    "    c_return_df = return_df.cumprod()\n",
    "    \n",
    "    #Setup fwd returns\n",
    "    fwd_1m_ret = fwd_return(c_return_df, -1)\n",
    "    \n",
    "    #Melted dfs\n",
    "    fwd_1m_ret_m = melt_df(fwd_1m_ret, 1)\n",
    "    fwd_1m_ret_m.columns = ['permno', '1m_fwd_ret', 'DATE']\n",
    "    return fwd_1m_ret_m.set_index(['permno', 'DATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "permno_list = list(set(big_data['permno'].to_list()))\n",
    "append_df = return_merge(permno_list, risk_free_df)\n",
    "big_data = big_data.set_index(['permno', 'DATE'])\n",
    "big_data = big_data.join(append_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mvel1       0.000724\n",
       "beta        0.097782\n",
       "bm          0.226370\n",
       "operprof    0.307127\n",
       "agr         0.278808\n",
       "sic2        0.052546\n",
       "dtype: float64"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_data[big_data.index.get_level_values('DATE') >= '1973-01-01'][['mvel1', 'beta', 'bm', 'operprof', 'agr', 'sic2']].isna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_data[big_data.index.get_level_values('DATE') >= '1973-01-01'].to_csv('C:/Users/andrew_lazzeri/Desktop/Project_Files/Data Upload/final_cross_section_df.csv')"
   ]
  }
 ],
 "metadata": {
  "datalore": {
   "base_environment": "default",
   "computation_mode": "JUPYTER",
   "package_manager": "pip",
   "packages": [],
   "version": 1
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
